{
 "metadata": {
  "name": "401. Harness machine learning with Scikit-Learn"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The goal is to build a machine that make decisions automatically\n",
      "using information it has not seen before, and whose performance\n",
      "improves with experience. The approach in machine learning is to \n",
      "develop algorithms that make decisions using a model fitted on data.\n",
      "\n",
      "# Machine learning is easy with Scikit-Learn\n",
      "The scikit-learn package is a collection of machine learning algorithms\n",
      "that share a common usage pattern:\n",
      "\n",
      "- Load data.\n",
      "- Pick model.\n",
      "- Fit model parameters to data.\n",
      "- Predict using fitted model."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import datasets, neighbors\n",
      "iris = datasets.load_iris()\n",
      "model = neighbors.KNeighborsClassifier()\n",
      "model.fit(iris.data, iris.target)\n",
      "model.predict([7.5, 3, 6.5, 2.1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- [Scikit-Learn Tutorials](http://scikit-learn.org/dev)\n",
      "- [Scikit-Learn Examples](http://scikit-learn.org/dev/auto_examples)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Take a moment to browse the official tutorials and examples"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Which model do we use?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.datasets import load_digits\n",
      "digits = load_digits()\n",
      "X, y = digits.data, digits.target\n",
      "trainingSet = X[:-100], y[:-100]\n",
      "testSet = X[-100:], y[-100:]\n",
      "\n",
      "def evaluate_model(model):\n",
      "    return model.fit(*trainingSet).score(*testSet)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.gaussian_process import GaussianProcess\n",
      "evaluate_model(GaussianProcess())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "0.74548917199754872"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.tree import DecisionTreeClassifier\n",
      "evaluate_model(DecisionTreeClassifier())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "0.84999999999999998"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.svm import SVC\n",
      "evaluate_model(SVC(kernel='linear', C=0.001))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 22,
       "text": [
        "0.98999999999999999"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Evaluate model performance with [cross-validation](http://scikit-learn.org/dev/model_selection.html)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import cross_val_score\n",
      "from sklearn.datasets import load_iris\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "\n",
      "iris = load_iris()\n",
      "model = LogisticRegression()\n",
      "cross_val_score(model, iris.data, iris.target)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 26,
       "text": [
        "array([ 0.94,  0.98,  0.98])"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cross_val_score(model, iris.data, iris.target, cv=4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 29,
       "text": [
        "array([ 0.92105263,  0.92105263,  0.91891892,  0.97297297])"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import LeaveOneOut\n",
      "\n",
      "cross_val_score(model, iris.data, iris.target, cv=LeaveOneOut(len(iris.target)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 31,
       "text": [
        "array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
        "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
        "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
        "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
        "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
        "        1.,  0.,  1.,  1.,  1.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
        "        1.,  1.,  1.,  1.,  1.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,\n",
        "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
        "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
        "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,\n",
        "        1.,  1.,  1.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
        "        1.,  1.,  1.,  1.,  1.,  1.,  1.])"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Evaluate stack performance with [pipelining](http://scikit-learn.org/dev/modules/pipeline.html)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.lib.display import YouTubeVideo\n",
      "YouTubeVideo('1uS5b8aQ6z8')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "\n",
        "            <iframe\n",
        "                width=\"400\"\n",
        "                height=\"300\"\n",
        "                src=\"http://www.youtube.com/embed/1uS5b8aQ6z8\"\n",
        "                frameborder=\"0\"\n",
        "                allowfullscreen\n",
        "            ></iframe>\n",
        "        "
       ],
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "<IPython.lib.display.YouTubeVideo at 0x33cda50>"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.decomposition import PCA\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.cross_validation import cross_val_score\n",
      "from sklearn.datasets import load_digits; digits = load_digits()\n",
      "\n",
      "model = Pipeline([\n",
      "    ('pca', PCA()), \n",
      "    ('logistic', LogisticRegression()),\n",
      "])\n",
      "np.mean(cross_val_score(model, digits.data, digits.target))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 42,
       "text": [
        "0.95770728992765708"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## [Transform](http://scikit-learn.org/dev/data_transforms.html) data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.preprocessing import StandardScaler\n",
      "\n",
      "model = Pipeline([\n",
      "    ('scaler', StandardScaler()),\n",
      "    ('pca', PCA()), \n",
      "    ('logistic', LogisticRegression()),\n",
      "])\n",
      "np.mean(cross_val_score(model, digits.data, digits.target))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 44,
       "text": [
        "0.96160267111853093"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's vectorize a stanza from Zbigniew Herbert's [A Knocker](http://www.poemhunter.com/poem/a-knocker/)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "\n",
      "vectorizer = CountVectorizer(min_df=1)\n",
      "documents = [\n",
      "    'my imagination',\n",
      "    'is a piece of board',\n",
      "    'my sole instrument',\n",
      "    'is a wooden stick',\n",
      "]\n",
      "X = vectorizer.fit_transform(documents)\n",
      "documentVectors = X.toarray()\n",
      "documentVectors"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 51,
       "text": [
        "array([[0, 1, 0, 0, 1, 0, 0, 0, 0, 0],\n",
        "       [1, 0, 0, 1, 0, 1, 1, 0, 0, 0],\n",
        "       [0, 0, 1, 0, 1, 0, 0, 1, 0, 0],\n",
        "       [0, 0, 0, 1, 0, 0, 0, 0, 1, 1]])"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "featureNames = vectorizer.get_feature_names()\n",
      "for bagOfWords in documentVectors:\n",
      "    print zip(featureNames, bagOfWords)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[(u'board', 0), (u'imagination', 1), (u'instrument', 0), (u'is', 0), (u'my', 1), (u'of', 0), (u'piece', 0), (u'sole', 0), (u'stick', 0), (u'wooden', 0)]\n",
        "[(u'board', 1), (u'imagination', 0), (u'instrument', 0), (u'is', 1), (u'my', 0), (u'of', 1), (u'piece', 1), (u'sole', 0), (u'stick', 0), (u'wooden', 0)]\n",
        "[(u'board', 0), (u'imagination', 0), (u'instrument', 1), (u'is', 0), (u'my', 1), (u'of', 0), (u'piece', 0), (u'sole', 1), (u'stick', 0), (u'wooden', 0)]\n",
        "[(u'board', 0), (u'imagination', 0), (u'instrument', 0), (u'is', 1), (u'my', 0), (u'of', 0), (u'piece', 0), (u'sole', 0), (u'stick', 1), (u'wooden', 1)]\n"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Optimize model parameters systematically with [Grid Search](http://scikit-learn.org/dev/modules/grid_search.html)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Adapted from \n",
      "# http://scikit-learn.org/dev/tutorial/statistical_inference/putting_together.html\n",
      "from sklearn import linear_model, decomposition, datasets\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "from sklearn.pipeline import Pipeline\n",
      "\n",
      "pipeline = Pipeline([\n",
      "    ('pca', decomposition.PCA()), \n",
      "    ('logistic', linear_model.LogisticRegression()),\n",
      "])\n",
      "gridSearch = GridSearchCV(pipeline, dict(\n",
      "    pca__n_components=[20, 40],\n",
      "    logistic__C=[1, 1000]))\n",
      "\n",
      "digits = datasets.load_digits()\n",
      "gridSearch.fit(digits.data, digits.target)\n",
      "valueByParameter = gridSearch.best_estimator_.get_params()\n",
      "for parameter in gridSearch.param_grid:\n",
      "    print '%s: %r' % (parameter, valueByParameter[parameter])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "logistic__C: 1\n",
        "pca__n_components: 40\n"
       ]
      }
     ],
     "prompt_number": 70
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Identify a translator of Zbigniew Herbert"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from archiveIO import Archive, TemporaryFolder\n",
      "\n",
      "archive = Archive('datasets/ZbigniewHerbert.tar.gz')\n",
      "documents = []\n",
      "categories = []\n",
      "with TemporaryFolder() as temporaryFolder:\n",
      "    for documentPath in archive.load(temporaryFolder):\n",
      "        text = open(documentPath).read()\n",
      "        documents.append(text)\n",
      "        categories.append('Carpenter' in text)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 93
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "from sklearn.feature_extraction.text import TfidfTransformer\n",
      "from sklearn.linear_model import SGDClassifier\n",
      "\n",
      "pipeline = Pipeline([\n",
      "    ('vect', CountVectorizer()),\n",
      "    ('tfidf', TfidfTransformer()),\n",
      "    ('clf', SGDClassifier()),\n",
      "])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 94
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "parameters = {\n",
      "    'vect__max_df': (0.5, 0.75, 1.0),\n",
      "    'vect__max_n': (1, 2),\n",
      "    'clf__alpha': (0.00001, 0.000001),\n",
      "    'clf__penalty': ('l2', 'elasticnet'),\n",
      "}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 95
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.grid_search import GridSearchCV\n",
      "\n",
      "gridSearch = GridSearchCV(pipeline, parameters, n_jobs=-1)\n",
      "gridSearch.fit(documents, categories)\n",
      "\n",
      "valueByParameter = gridSearch.best_estimator_.get_params()\n",
      "for parameter in gridSearch.param_grid:\n",
      "    print '%s: %r' % (parameter, valueByParameter[parameter])\n",
      "print \"Best score: %0.3f\" % gridSearch.best_score_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "clf__penalty: 'l2'\n",
        "clf__alpha: 1e-05\n",
        "vect__max_n: 1\n",
        "vect__max_df: 0.5\n",
        "Best score: 0.833\n"
       ]
      }
     ],
     "prompt_number": 101
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print documents[27]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "A Knocker\n",
        "by Zbigniew Herbert\n",
        "translated from Polish by Czeslaw Milosz and Peter Dale Scott\n",
        "\n",
        "There are those who grow\n",
        "gardens in their heads\n",
        "paths lead from their hair\n",
        "to sunny and white cities\n",
        "\n",
        "it's easy for them to write\n",
        "they close their eyes\n",
        "immediately schools of images\n",
        "stream down from their foreheads\n",
        "\n",
        "my imagination\n",
        "is a piece of board\n",
        "my sole instrument\n",
        "is a wooden stick\n",
        "\n",
        "I strike the board\n",
        "it answers me\n",
        "yes--yes\n",
        "no--no\n",
        "\n",
        "for others the green bell of a tree\n",
        "the blue bell of water\n",
        "I have a knocker\n",
        "from unprotected gardens\n",
        "\n",
        "I thump on the board\n",
        "and it prompts me\n",
        "with the moralist's dry poem\n",
        "yes--yes\n",
        "no--no\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 92
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- [Scikit-Learn Documentation](http://scikit-learn.org/dev/)"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}